#suppose we want to test whether a certain type of genotype on a plant has the chance of .75 to occurs
#the data consist of genotype "a" appeared on 243 plants while the "b" genotype appeared on 682 plants.
#test is conducted to test for "b" genotype having the probability of .75 to appear on the species of the plant
binom.test(682, 682+243, .75)
##using approximation with normal distribution
#test statistic using quantile based on normal distribution
quantil = function(n,p,q){
nr <- round(n)
if (any(is.na(n) | (n < 0)) || max(abs(n - nr)) > 1e-07)
stop("'n' must be nonnegative and integer")
n <- nr
if (!missing(p) && (length(p) > 1L || is.na(p) || p < 0 ||
p > 1))
stop("'p' must be a single number between 0 and 1")
if (!missing(q) && (length(q) > 1L || is.na(q) || q < 0 ||
q > 1))
stop("'q' must be a single number between 0 and 1")
quant = n * p + qnorm(q)*sqrt(n*p*(1-p))
structure(quant)
}
quantil(925, .75, .025)
quantil(925, .75, .975)#upper quantile
#using the above quantile, pvalue from normal distribution approximation can be derived as
dnorm(-.8452)
#using the above quantile, pvalue from normal distribution approximation can be derived as
dnorm(-.8542)
#using the above quantile, pvalue from normal distribution approximation can be derived as
qnorm(-.8542)
#using the above quantile, pvalue from normal distribution approximation can be derived as
pnorm(-.8542)
#using the above quantile, pvalue from normal distribution approximation can be derived as
pnorm((682-.75*925+.5)/(925*.75*.25))
#using the above quantile, pvalue from normal distribution approximation can be derived as
pnorm((682-.75*925+.5)/sqrt(925*.75*.25))
###Binomial Test###
##exact method using stats library
library(stats)
binom.test
#confidence interval for probability or proportion of population
conf_int = function(y,n,alpha){
DNAME <- deparse1(substitute(x))
yr <- round(y)
if (any(is.na(y) | (y < 0)) || max(abs(y - yr)) > 1e-07)
stop("'y' must be nonnegative and integer")
y <- yr
if (length(y) == 2L) {
n <- sum(y)
y <- y[1L]
}
else if (length(x) == 1L) {
nr <- round(n)
if ((length(n) > 1L) || is.na(n) || (n < 1) || abs(n -
nr) > 1e-07 || (x > nr))
stop("'n' must be a positive integer >= 'x'")
DNAME <- paste(DNAME, "and", deparse1(substitute(n)))
n <- nr
}
else stop("incorrect length of 'y'")
if (!missing(alpha) && (length(alpha) > 1L || is.na(alpha) || alpha < 0 ||
alpha > 1))
stop("'alpha' must be a single number between 0 and 1")
quant_diff = qnorm(1-(alpha/2))*sqrt(y*(n-y)/n^3)
upper = y/n+quant_diff
lower = y/n-quant_diff
structure(list(Upper = upper, Lower = lower))
}
conf_int(7, 20, .05)
#confidence interval for probability or proportion of population
conf_int = function(y,n,alpha){
DNAME <- deparse1(substitute(y))
yr <- round(y)
if (any(is.na(y) | (y < 0)) || max(abs(y - yr)) > 1e-07)
stop("'y' must be nonnegative and integer")
y <- yr
if (length(y) == 2L) {
n <- sum(y)
y <- y[1L]
}
else if (length(x) == 1L) {
nr <- round(n)
if ((length(n) > 1L) || is.na(n) || (n < 1) || abs(n -
nr) > 1e-07 || (x > nr))
stop("'n' must be a positive integer >= 'y'")
DNAME <- paste(DNAME, "and", deparse1(substitute(n)))
n <- nr
}
else stop("incorrect length of 'y'")
if (!missing(alpha) && (length(alpha) > 1L || is.na(alpha) || alpha < 0 ||
alpha > 1))
stop("'alpha' must be a single number between 0 and 1")
quant_diff = qnorm(1-(alpha/2))*sqrt(y*(n-y)/n^3)
upper = y/n+quant_diff
lower = y/n-quant_diff
structure(list(Upper = upper, Lower = lower))
}
conf_int(7, 20, .05)
#confidence interval for probability or proportion of population
conf_int = function(y,n,alpha){
DNAME <- deparse1(substitute(y))
yr <- round(y)
if (any(is.na(y) | (y < 0)) || max(abs(y - yr)) > 1e-07)
stop("'y' must be nonnegative and integer")
y <- yr
if (length(y) == 2L) {
n <- sum(y)
y <- y[1L]
}
else if (length(y) == 1L) {
nr <- round(n)
if ((length(n) > 1L) || is.na(n) || (n < 1) || abs(n -
nr) > 1e-07 || (y > nr))
stop("'n' must be a positive integer >= 'y'")
DNAME <- paste(DNAME, "and", deparse1(substitute(n)))
n <- nr
}
else stop("incorrect length of 'y'")
if (!missing(alpha) && (length(alpha) > 1L || is.na(alpha) || alpha < 0 ||
alpha > 1))
stop("'alpha' must be a single number between 0 and 1")
quant_diff = qnorm(1-(alpha/2))*sqrt(y*(n-y)/n^3)
upper = y/n+quant_diff
lower = y/n-quant_diff
structure(list(Upper = upper, Lower = lower))
}
conf_int(7, 20, .05)
conf_int(4, 20, .05)
###Quantile test###
##from : https://people.stat.sc.edu/hitchcock/Rexamples518section3_2.txt
quantile.test<-function(x,xstar=0,quantile=.5,alternative="two.sided"){
n<-length(x)
p<-quantile
T1<-sum(x<=xstar)
T2<-sum(x< xstar)
if (alternative=="quantile.less") {
p.value<-1-pbinom(T2-1,n,p)}
if (alternative=="quantile.greater"){
p.value<-pbinom(T1,n,p)}
if (alternative=="two.sided"){
p.value<-2*min(1-pbinom(T2-1,n,p),pbinom(T1,n,p))}
list(xstar=xstar,alternative=alternative,T1=T1,T2=T2,p.value=p.value)
}
#an example case for this test is, say there are students with their test score recorded.
#then we would like to inspect whether the quartile of the scores is 193
testscores <- c(189,233,195,160,212,176,231,185,199,213,202,193,174,166,248)
quantile.test(testscores,xstar=193,quantile=0.75,alternative="two.sided")
#another example is for testing one-tailed quantile.
#suppose we have prices for houses within a neighborhood, then we want to test whether the median
#of the house price is at least 179
prices <- c(120, 500, 64, 104, 172, 275, 336, 55, 535, 251, 214, 1250, 402, 27, 109, 17, 334, 205)
quantile.test(prices,xstar=179, quantile=0.5, alternative="quantile.less")
sort(prices)
##confidence interval for quantile
#to make the (1-alpha) confidence interval for certain quantile
quantile.interval<-function(x,quantile=.5,conf.level=.95){
n<-length(x)
p<-quantile
alpha<-1-conf.level
rmin1<-qbinom(alpha/2,n,p)-1
r<-rmin1+1
alpha1<-pbinom(r-1,n,p)
smin1<-qbinom(1-alpha/2,n,p)
s<-smin1+1
alpha2<-1-pbinom(s-1,n,p)
clo<-sort(x)[r]
chi<-sort(x)[s]
conf.level<-1-alpha1-alpha2
list(quantile=quantile,conf.level=conf.level,r=r,s=s,interval=c(clo,chi))}
#example with the house prices : 95% CI for median
quantile.interval(prices)
#example with the house prices : 95% CI for median
quantile.interval(prices, .5, .95)
#example with the house prices : 90% CI for .7 quantile
quantile.interval(prices, .7, .9)
##sign test
#in a sense sign test is simply another kind of binomial test. the importance to be remembered is
#this test, most of the time, is used for paired data. thus, it is also similar to t-test for paired samples
library(tidyverse)
library(rstatix)
library(ggpubr)
install.packages("datarium")
data(mice2, datarium)
data("mice2", package = datarium)
library(datarium)
data(mice2)
mice2
mice2 = mice2 %>%
gather(key = "group", value = "weight", before, after)
head(mice2, 3)
#summarize
mice2 = %>$
group_by(group)%>%
mean
View(mice2)
#summarize
mice2 %>$
group_by(group)%>%
mean
#summarize
mice2 %>$
group_by(group)%>%
mean(weight)
#summarize
mice2 %>$
group_by(group)%>%
mean(weight)
#summarize
mice2%>$group_by(group)%>%mean(weight)
#summarize
mice2%>$group_by(group)%>%summarise(mean_weight = mean(weight))
mice2 %>%
group_by(group) %>%
get_summary_stats(weight, type = "median_iqr")
#summarize
mice2 %>% group_by(group) %>% summarise(mean_weight = mean(weight))
#summarize
mice2 %>% group_by(group) %>% summarise(mean_weight = mean(weight),
median_weight = median(weight))
#summarize
mice2 %>% group_by(group) %>% summarise(n = n(weight),
mean_weight = mean(weight),
median_weight = median(weight))
n(mice)
n(prices)
count(prices)
summary(prices)
length(mice2$weight)
#summarize
mice2 %>% group_by(group) %>% summarise(n = length(weight),
mean_weight = mean(weight),
median_weight = median(weight))
#summarize
mice2 %>% group_by(group) %>% summarise(n = length(weight),
mean_weight = mean(weight),
median_weight = median(weight),
iqr = IQR(weight))
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
stat.test = mice2 %>%
sign_test(weight ~ group) %>%
add_significance()
stat.test
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(weight ~ group)
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(mice2, weight ~ group)
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(mice2, weight ~ group, alternative = "right tail")
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(mice2, weight ~ group, alternative = "greater")
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(mice2, weight ~ group, alternative = "less")
#based on the above summary, it can be seen the big difference in mean and median values for the
#weight of specimens before adn after treatment
#now we use the statistics test for sign test
sign_test(mice2, weight ~ group, alternative = "greater")
##sign test exercise from chapter 3.4 W. J. Conover - Practical Nonparametric Statistics, 3rd (1999, Wiley)
# 2
binom.test(22,28)
##sign test exercise from chapter 3.4 W. J. Conover - Practical Nonparametric Statistics, 3rd (1999, Wiley)
# 2
binom.test(22,28, alternative = "greater")
##sign test exercise from chapter 3.4 W. J. Conover - Practical Nonparametric Statistics, 3rd (1999, Wiley)
# 2
binom.test(22,28, alternative = "less")
##sign test exercise from chapter 3.4 W. J. Conover - Practical Nonparametric Statistics, 3rd (1999, Wiley)
# 2
binom.test(22,28, alternative = "greater")
# 3
binom.test(77,100)
#reaction time after lunch being longer than reaction time before lunch
# 3
binom.test(77,100) #evidently there is significant difference of durability affected by two of the additives
#reaction time after lunch being longer than reaction time before lunch
# 3
binom.test(23,100) #evidently there is significant difference of durability affected by two of the additives
# 4
binom.test(7, 22)
# 4
binom.test(12, 22)
